{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Tj2Z6MN_P9W"
   },
   "source": [
    "# 6.4610 Research Project\n",
    "\n",
    "## Overview\n",
    "In this file, we implement a transformer model trained on OpenWebText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHmeYniHCpHz"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 36895,
     "status": "ok",
     "timestamp": 1763573073406,
     "user": {
      "displayName": "Mohamed Wacyl Meddour",
      "userId": "07424742655467060070"
     },
     "user_tz": 300
    },
    "id": "spHhrEHz_P9X",
    "outputId": "a4429f50-566e-49ae-94f8-59386a4e50d0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Tuple, Union, Optional, List, Dict\n",
    "import math\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from itertools import islice\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDMbe1yh9SP4"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msTYZcSc-eoj"
   },
   "outputs": [],
   "source": [
    "train_dataset_size = 200000\n",
    "test_dataset_size = 10000\n",
    "last_trained_epoch = 0\n",
    "PH_ALPHA = 0.45\n",
    "PH_SEMANTIC_HEADS = 3\n",
    "\n",
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    \"\"\"Configuration class for transformer model\"\"\"\n",
    "    vocab_size: int = 50257\n",
    "    hidden_size: int = 768\n",
    "    num_attention_heads: int = 12\n",
    "    num_hidden_layers: int = 12\n",
    "    intermediate_size: int = 3072\n",
    "    max_position_embeddings: int = 512\n",
    "    use_causal_mask: bool = True\n",
    "    number_diffusion_kernels = 4\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    # Model hyperparameters\n",
    "    vocab_size: int = 50257\n",
    "    hidden_size: int = 768\n",
    "    num_attention_heads: int = 12\n",
    "    num_hidden_layers: int = 12\n",
    "    intermediate_size: int = 3072\n",
    "    max_position_embeddings: int = 512\n",
    "    use_causal_mask: bool = True\n",
    "\n",
    "    # Training hyperparameters\n",
    "    batch_size: int = 4\n",
    "    learning_rate: float = 5e-4\n",
    "    weight_decay: float = 0.01\n",
    "    num_epochs: int = 3\n",
    "    steps_per_epoch: int = 200000\n",
    "    warmup_steps: int = 1000\n",
    "    max_grad_norm: float = 1.0\n",
    "    save_steps: int = 10000\n",
    "    eval_steps: int = 5000\n",
    "    train_dataset_size: int = 200000\n",
    "    test_dataset_size: int = 10000\n",
    "\n",
    "    # Paths\n",
    "    output_dir: str = \"/transformer_ph_small\"\n",
    "    log_dir: str = \"/logs_transformer_ph_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGEqdw4n80aD"
   },
   "outputs": [],
   "source": [
    "class PHFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_size: int, intermediate_size: int):\n",
    "        \"\"\"\n",
    "        Position-wise feed-forward network\n",
    "\n",
    "        Args:\n",
    "            hidden_size: Model dimension\n",
    "            intermediate_size: Hidden dimension of FFN\n",
    "            activation_fn: Activation function ('relu', 'gelu', etc.)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.GELU()\n",
    "        self.linear1 = nn.Linear(hidden_size, intermediate_size)\n",
    "        self.linear2 = nn.Linear(intermediate_size, hidden_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class TrainingMetrics:\n",
    "    \"\"\"Track training metrics\"\"\"\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.learning_rates = []\n",
    "        self.step = 0\n",
    "\n",
    "    def update(self, loss: float, lr: float):\n",
    "        self.losses.append(loss)\n",
    "        self.learning_rates.append(lr)\n",
    "        self.step += 1\n",
    "\n",
    "    def get_avg_loss(self, last_n: int = 100):\n",
    "        if len(self.losses) == 0:\n",
    "            return 0.0\n",
    "        return np.mean(self.losses[-last_n:])\n",
    "\n",
    "\n",
    "# Custom dataset class for on-the-fly tokenization\n",
    "class PHDataset:\n",
    "    def __init__(self, dataset, tokenizer, max_length=512, max_samples=None):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.max_samples = max_samples\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "\n",
    "        for each in self.dataset:\n",
    "            text = each['text']\n",
    "\n",
    "            # Tokenize on the fly\n",
    "            encoded = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'  # Return tensors for direct use\n",
    "            )\n",
    "\n",
    "            # Create labels (same as input_ids for causal language modeling)\n",
    "            labels = encoded['input_ids'].clone()\n",
    "\n",
    "            yield {\n",
    "                'input_ids': encoded['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "                'labels': labels.squeeze(0)  # Remove batch dimension\n",
    "            }\n",
    "\n",
    "            count += 1\n",
    "            if self.max_samples is not None and count >= self.max_samples:\n",
    "                break\n",
    "\n",
    "\n",
    "def evaluate_model(model, tokenizer, test_prompts: List[str], temperature: float = 0.7):\n",
    "    \"\"\"Evaluate model with test prompts\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get device from model parameters\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    print(\"Generating samples from trained model:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, prompt in enumerate(test_prompts):\n",
    "        print(f\"\\nPrompt {i+1}: '{prompt}'\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # Tokenize prompt\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "        # Generate with different temperatures\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=150,\n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "            generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "            print(f\"Temperature {temperature}: {generated_text}\")\n",
    "            print()\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, test_prompts_iter: iter, batch_size: int = 16, max_length: int = 512):\n",
    "    \"\"\"\n",
    "    Calculate perplexity of model with test prompts in a batched way.\n",
    "    Applies attention mask so that only valid tokens contribute to the loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    print(\"Calculating perplexity of model with test prompts (batched):\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    test_prompts = [sample['text'] for sample in test_prompts_iter]\n",
    "\n",
    "    # Tokenize all prompts at once (batched)\n",
    "    encodings = tokenizer(\n",
    "        test_prompts,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding='longest',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings.get('attention_mask', None)\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "    num_samples = input_ids.size(0)\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start in tqdm(range(0, num_samples, batch_size)):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_input_ids = input_ids[start:end]\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(batch_input_ids)\n",
    "            if isinstance(logits, tuple):\n",
    "                logits = logits[0]\n",
    "\n",
    "            # Shift logits and labels for causal language modeling\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = batch_input_ids[..., 1:].contiguous()\n",
    "            if attention_mask is not None:\n",
    "                batch_attention_mask = attention_mask[start:end]\n",
    "                shift_mask = batch_attention_mask[..., 1:].contiguous()\n",
    "            else:\n",
    "                shift_mask = None\n",
    "\n",
    "            # Flatten for loss computation\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = loss_fct(\n",
    "                shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                shift_labels.view(-1)\n",
    "            )  # (batch * seq_len-1,)\n",
    "\n",
    "            if shift_mask is not None:\n",
    "                loss = loss * shift_mask.view(-1).float()\n",
    "                num_valid = shift_mask.sum().item()\n",
    "            else:\n",
    "                num_valid = shift_labels.numel()\n",
    "\n",
    "            total_loss += loss.sum().item()\n",
    "            total_tokens += num_valid\n",
    "\n",
    "    avg_loss = total_loss / max(1, total_tokens)\n",
    "    avg_perplexity = float(torch.exp(torch.tensor(avg_loss)))\n",
    "    print(f\"Average Perplexity: {avg_perplexity:.4f}\")\n",
    "    return avg_perplexity\n",
    "\n",
    "\n",
    "def save_model(model, tokenizer, optimizer, scheduler, save_path: str):\n",
    "    \"\"\"Save model and tokenizer\"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_path, \"model.pt\"))\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_path, \"optimizer.pt\"))\n",
    "    torch.save(scheduler.state_dict(), os.path.join(save_path, \"scheduler.pt\"))\n",
    "    if hasattr(model, 'config'):\n",
    "        torch.save(model.config.__dict__, os.path.join(save_path, \"config.json\"))\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "def load_model(model, load_path: str):\n",
    "    \"\"\"Load model weights\"\"\"\n",
    "    model.load_state_dict(torch.load(os.path.join(load_path, \"model.pt\")))\n",
    "    print(f\"Model loaded from {load_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8m_lg4P_P9Y"
   },
   "source": [
    "## RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wv78Yip4_P9Z"
   },
   "outputs": [],
   "source": [
    "class PHRMSNorm(nn.Module):\n",
    "    def __init__(self, hidden_size: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        RMS Normalization\n",
    "\n",
    "        Args:\n",
    "            hidden_size: The size of the hidden dimension\n",
    "            eps: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.parameter = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply RMS normalization\n",
    "\n",
    "        Args:\n",
    "            hidden_states: Input tensor of shape (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            Normalized tensor of shape (batch_size, seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        rms = torch.sqrt(torch.mean(torch.square(hidden_states), dim=-1, keepdim=True) + self.eps)\n",
    "        normalized = hidden_states / rms\n",
    "        return normalized * self.parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85mvBER5_P9a"
   },
   "source": [
    "## Attention Mechanisms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-xBHOSc-HJ3"
   },
   "source": [
    "### Single Attention Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjdU460W_P9b"
   },
   "outputs": [],
   "source": [
    "class PHAttentionHead(nn.Module):\n",
    "    def __init__(self, hidden_size: int,\n",
    "                 head_dim: int,\n",
    "                 repn_dim: int = 64,  # Dimension of representation vectors\n",
    "                 k: int = 32,         # K-nearest neighbors (GLOBAL over batch)\n",
    "                 alpha: float = PH_ALPHA,  # Bias importance\n",
    "                 sim_mode: str = \"dot\",  # \"dot\" or \"l2\"\n",
    "                 semantic: bool = True    # False = normal head\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.head_dim = head_dim\n",
    "        self.semantic = semantic\n",
    "\n",
    "        self.WQ = nn.Linear(hidden_size, head_dim, bias=False)\n",
    "        self.WK = nn.Linear(hidden_size, head_dim, bias=False)\n",
    "        self.WV = nn.Linear(hidden_size, head_dim, bias=False)\n",
    "\n",
    "        if semantic:\n",
    "            self.WR = nn.Linear(hidden_size, repn_dim, bias=False)\n",
    "            self.k = k\n",
    "            self.r = min(self.k, 32)  # small projection rank\n",
    "            self.U_raw = nn.Parameter(torch.randn(self.k, self.r) / math.sqrt(self.k))\n",
    "            self.alpha = alpha\n",
    "            self.sim_mode = sim_mode\n",
    "\n",
    "\n",
    "    def _mst_h0_lifetimes(self, dmats: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Batched Prim's algorithm to get H0 VR lifetimes (merge heights) from\n",
    "        distance matrices. Exact for H0. Vectorized over batch of neighborhoods.\n",
    "\n",
    "        dmats: (N, m, m) symmetric with 0 diag\n",
    "        returns: (N, m-1) lifetimes (MST edge weights)\n",
    "        \"\"\"\n",
    "        N, m, _ = dmats.shape\n",
    "        device = dmats.device\n",
    "\n",
    "        visited = torch.zeros(N, m, dtype=torch.bool, device=device)\n",
    "        visited[:, 0] = True\n",
    "\n",
    "        d_to_tree = dmats[:, 0, :].clone()  # (N, m)\n",
    "        d_to_tree[visited] = float('inf')\n",
    "\n",
    "        lifetimes = []\n",
    "        arangeN = torch.arange(N, device=device)\n",
    "\n",
    "        for _ in range(m - 1):\n",
    "            best_val, best_idx = d_to_tree.min(dim=1)   # (N,), (N,)\n",
    "            lifetimes.append(best_val)\n",
    "            visited[arangeN, best_idx] = True\n",
    "            new_row = dmats[arangeN, best_idx, :]       # (N, m)\n",
    "            d_to_tree = torch.minimum(d_to_tree, new_row)\n",
    "            d_to_tree[visited] = float('inf')\n",
    "\n",
    "        return torch.stack(lifetimes, dim=1)            # (N, m-1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: Optional[torch.Tensor] = None\n",
    "               ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        x: (B, L, hidden_size)\n",
    "        attn_mask: (B, L, L)\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape\n",
    "\n",
    "        # standard attention\n",
    "        Q = self.WQ(x)  # (B, L, head_dim)\n",
    "        K = self.WK(x)  # (B, L, head_dim)\n",
    "        V = self.WV(x)  # (B, L, head_dim)\n",
    "        score = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)  # (B, L, L)\n",
    "\n",
    "        if self.semantic:\n",
    "            # PH features (H0 via MST) computed over the WHOLE BATCH\n",
    "            repn = self.WR(x)                                 # (B, L, repn_dim)\n",
    "            N = B * L\n",
    "            repn_flat = repn.reshape(N, -1).contiguous()      # (N, repn_dim)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # GLOBAL kNN across all tokens in the batch\n",
    "                D_all = torch.cdist(repn_flat, repn_flat, p=2)             # (N, N)\n",
    "                k_eff = min(self.k, max(1, N - 1))\n",
    "                knn_idx = D_all.topk(k_eff + 1, largest=False).indices     # (N, k+1), includes self\n",
    "\n",
    "                # neighborhoods and their pairwise distances\n",
    "                m = knn_idx.size(1)                                         # m = k_eff + 1\n",
    "                row = knn_idx.unsqueeze(-1).expand(-1, m, m)               # (N, m, m)\n",
    "                col = knn_idx.unsqueeze(-2).expand(-1, m, m)               # (N, m, m)\n",
    "                dmats = D_all[row, col].contiguous()\n",
    "\n",
    "            # H0 lifetimes via batched MST\n",
    "            lifetimes = self._mst_h0_lifetimes(dmats)  # (N, m-1) = (N, k_eff)\n",
    "\n",
    "            # pad to fixed length k and normalize\n",
    "            k_eff_actual = m - 1\n",
    "            if k_eff_actual < self.k:\n",
    "                pad = torch.zeros(N, self.k - k_eff_actual,\n",
    "                                   device=x.device, dtype=lifetimes.dtype)\n",
    "                lifetimes = torch.cat([lifetimes, pad], dim=1)  # (N, k)\n",
    "\n",
    "            Phi = torch.nn.functional.normalize(lifetimes, p=2, dim=-1).view(B, L, self.k)  # (B, L, k)\n",
    "\n",
    "            Phi_c = Phi - Phi.mean(dim=1, keepdim=True)                     # (B, L, k)\n",
    "            U = self.U_raw / (self.U_raw.norm(p='fro') + 1e-8)              # (k, r), scale-normalized\n",
    "            Z = torch.matmul(Phi_c, U)                                       # (B, L, r)\n",
    "            Z = torch.nn.functional.normalize(Z, p=2, dim=-1)               # (B, L, r)\n",
    "\n",
    "            # bias from Z\n",
    "            if self.sim_mode == \"dot\":\n",
    "                ph_bias = torch.bmm(Z, Z.transpose(1, 2))                   # (B, L, L)\n",
    "            else:  # \"l2\"\n",
    "                d = torch.cdist(Z, Z, p=2)\n",
    "                ph_bias = -(d ** 2)\n",
    "\n",
    "            score = score + self.alpha * ph_bias\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            score = score.masked_fill(attn_mask == 0, float('-inf'))\n",
    "        attention_weights = torch.softmax(score, dim=-1)\n",
    "        attention_output = torch.matmul(attention_weights, V)\n",
    "        return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj5oGBUX_P9b"
   },
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atALg9xP_P9b"
   },
   "outputs": [],
   "source": [
    "class PHMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_heads: int):\n",
    "        \"\"\"\n",
    "        Multi-head attention implementation\n",
    "\n",
    "        Args:\n",
    "            hidden_size: Model dimension\n",
    "            num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert hidden_size % num_heads == 0, f\"The hidden size {hidden_size} is not divisible by the number of heads {num_heads}.\"\n",
    "        head_dim = hidden_size // num_heads\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.heads = nn.ModuleList([PHAttentionHead(hidden_size, head_dim, semantic=True) for __ in range(PH_SEMANTIC_HEADS)]+[PHAttentionHead(hidden_size, head_dim, semantic=False) for _ in range(num_heads-PH_SEMANTIC_HEADS)])\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass for multi-head attention\n",
    "\n",
    "        Args:\n",
    "            hidden_states: Input tensor (batch_size, seq_len, hidden_size)\n",
    "            attention_mask: Attention mask (batch_size, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            attention_output: (batch_size, seq_len, hidden_size)\n",
    "            attention_weights: (batch_size, num_heads, seq_len, seq_len)\n",
    "        \"\"\"\n",
    "        outputs = [each(hidden_states, attention_mask) for each in self.heads]\n",
    "        attention_outputs_tuple = tuple(each[0] for each in outputs)\n",
    "        attention_outputs = torch.stack(attention_outputs_tuple).transpose(0, 1).transpose(1, 2).flatten(2, 3)\n",
    "        attention_weights_tuple = tuple(each[1] for each in outputs)\n",
    "        attention_weights = torch.stack(attention_weights_tuple).transpose(0, 1)\n",
    "        attention_outputs = self.linear(attention_outputs)\n",
    "        return attention_outputs, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JGaZYl3_P9c"
   },
   "source": [
    "## Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGmyVRtR_P9c"
   },
   "outputs": [],
   "source": [
    "class PHTransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_heads: int, intermediate_size: int):\n",
    "        \"\"\"\n",
    "        Complete transformer block with attention and feed-forward\n",
    "\n",
    "        Args:\n",
    "            hidden_size: Model dimension\n",
    "            num_heads: Number of attention heads\n",
    "            intermediate_size: FFN hidden dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.rms_att = PHRMSNorm(hidden_size=hidden_size)\n",
    "        self.rms_ffn = PHRMSNorm(hidden_size=hidden_size)\n",
    "        self.mha = PHMultiHeadAttention(hidden_size=hidden_size, num_heads=num_heads)\n",
    "        self.ffn = PHFeedForward(hidden_size=hidden_size, intermediate_size=intermediate_size)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for transformer block\n",
    "\n",
    "        Args:\n",
    "            hidden_states: Input tensor (batch_size, seq_len, hidden_size)\n",
    "            attention_mask: Attention mask\n",
    "\n",
    "        Returns:\n",
    "            hidden_states: Output tensor (batch_size, seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        att_norm = self.rms_att(hidden_states)\n",
    "        self_att = self.mha(att_norm, attention_mask)[0]\n",
    "        res_conn_self_att = self_att + hidden_states\n",
    "        ffn_norm = self.rms_ffn(res_conn_self_att)\n",
    "        ffn_output = self.ffn(ffn_norm)\n",
    "        res_conn_ffn = res_conn_self_att + ffn_output\n",
    "        return res_conn_ffn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmLnUrtQ_P9c"
   },
   "source": [
    "## Complete Transformer Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UrEnEwp-lzr"
   },
   "source": [
    "### `create_causal_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNKHVXuc_P9c"
   },
   "outputs": [],
   "source": [
    "def create_causal_mask(seq_len: int, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"Create a causal (lower triangular) attention mask\n",
    "\n",
    "    Args:\n",
    "        seq_len: Sequence length\n",
    "        device: Device to create the mask on\n",
    "\n",
    "    Returns:\n",
    "        Causal mask of shape (1, seq_len, seq_len)\n",
    "    \"\"\"\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
    "    return mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4ecAmFBXVx0"
   },
   "source": [
    "### TransformerModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9xalskN_P9c"
   },
   "outputs": [],
   "source": [
    "class PHTransformerModel(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        \"\"\"\n",
    "        Complete transformer model for causal language modeling\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.embeddings = nn.Embedding(num_embeddings=self.config.vocab_size, embedding_dim=self.config.hidden_size)\n",
    "        self.pos_embeddings = nn.Embedding(num_embeddings=self.config.max_position_embeddings, embedding_dim=self.config.hidden_size)\n",
    "        self.transformer = nn.ModuleList([PHTransformerBlock(hidden_size=self.config.hidden_size, num_heads=self.config.num_attention_heads, intermediate_size=self.config.intermediate_size)\n",
    "         for _ in range(self.config.num_hidden_layers)])\n",
    "        self.norm = PHRMSNorm(hidden_size=self.config.hidden_size)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for transformer model\n",
    "\n",
    "        Args:\n",
    "            input_ids: Token IDs (batch_size, seq_len)\n",
    "            attention_mask: Attention mask (batch_size, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            hidden_states: Final hidden states (batch_size, seq_len, hidden_size)\n",
    "        \"\"\"\n",
    "        positions = torch.arange(input_ids.shape[1], device=input_ids.device).unsqueeze(0).expand(input_ids.size(0), -1)\n",
    "        pos_embeds = self.pos_embeddings(positions)\n",
    "        token_embeddings = self.embeddings(input_ids) + pos_embeds\n",
    "        if attention_mask is None and self.config.use_causal_mask:\n",
    "          attention_mask = create_causal_mask(input_ids.shape[1], token_embeddings.device)\n",
    "        transf = token_embeddings\n",
    "        for layer in self.transformer:\n",
    "          transf = layer(transf, attention_mask=attention_mask)\n",
    "        output = self.norm(transf)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlvCyZdoXYji"
   },
   "source": [
    "### CausalLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfYgs4iu_P9d"
   },
   "outputs": [],
   "source": [
    "class PHCausalLanguageModel(nn.Module):\n",
    "    def __init__(self, config: TransformerConfig):\n",
    "        \"\"\"Causal language model with transformer backbone\"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = PHTransformerModel(config)\n",
    "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, labels: Optional[torch.Tensor] = None) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass for language model\n",
    "\n",
    "        Args:\n",
    "            input_ids: Token IDs (batch_size, seq_len)\n",
    "            labels: Target labels for loss computation (batch_size, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            If labels provided: (loss, logits)\n",
    "            Else: logits only\n",
    "        \"\"\"\n",
    "        hidden_states = self.transformer(input_ids)\n",
    "        logits = self.lm_head(hidden_states)\n",
    "        if labels is not None:\n",
    "            logits_flat = logits[:, :-1, :].flatten(0, 1)\n",
    "            labels_flat = labels[:, 1:].flatten(0, 1)\n",
    "            return self.criterion(logits_flat, labels_flat), logits\n",
    "        return logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, input_ids: torch.Tensor, max_new_tokens: int = 100, temperature: float = 1.0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate text using the language model\n",
    "\n",
    "        Args:\n",
    "            input_ids: Starting token IDs (batch_size, seq_len)\n",
    "            max_new_tokens: Maximum number of tokens to generate\n",
    "            temperature: Sampling temperature\n",
    "\n",
    "        Returns:\n",
    "            Generated token IDs (batch_size, seq_len + max_new_tokens)\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self.forward(input_ids)[:, -1, :] / temperature\n",
    "            probs = nn.functional.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, 1)\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "        return input_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwxknteJ_P9d"
   },
   "source": [
    "## Transformer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223,
     "referenced_widgets": [
      "b96a0bb4e33f42d88196088d17902387",
      "7260ce838d23451ba3b1353a0df4cbb0",
      "f1fd811e4785435fa33de6cbac5593fa",
      "49040a59df664a2db3c17411200caff2",
      "c708368d6e494fd4a1d5220e19028e6a",
      "c78a5cdfcc80435798749ba565d322be",
      "09a29d17df674f01a23b9267fd458a32",
      "328cef6191204f3e94d4242035d1c2ad",
      "851d70362c3f4c26b7a7d2f6fb7b5437",
      "c0bc93ebf5c54636b6800e60ef1d70e2",
      "0508a805320e4b4d8c7d3410e52e7c21",
      "f03acc2297f64cbdba706836d01084af",
      "5628be3526df4351a3a5cf94e47745bf",
      "f00513a3d5db40709ddefddddf091b82",
      "bef19581a0b4433085fb277806243098",
      "5526feace396405a82db63a98ced30f5",
      "a34e2990c8544d74a1fe03ae2a0d4065",
      "17a6ae837e5041cfafddd5f21dee5c3a",
      "5885030f40514cfc820bddf20066a798",
      "df03abfda00c4d09b6d70d8f5146f2bf",
      "cdab7e2797c543e39dbace5b167f5f38",
      "5711a06b34b14746afa43ce406ce4dda"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2052,
     "status": "ok",
     "timestamp": 1763573097445,
     "user": {
      "displayName": "Mohamed Wacyl Meddour",
      "userId": "07424742655467060070"
     },
     "user_tz": 300
    },
    "id": "q-RixqK-Ai46",
    "outputId": "c14e7d63-2b22-4b01-9952-dff49590604f"
   },
   "outputs": [],
   "source": [
    "print(\"Loading OpenWebText dataset...\")\n",
    "dataset = datasets.load_dataset(\"openwebtext\", split=\"train\", streaming=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "7638dd52ee9042c7a6e2c1df86c6b9dd",
      "0a96728fefb5449496806bca2c544a0e",
      "6255af0f1ef9417c99947d01ccfa5152",
      "3fec9cb83a4140b8b8491a9214195d19",
      "375354433c264d68bbb3af9e186e877d",
      "37bd2023b2fb476cbcd4640f8423bba8",
      "61cc246856b44c71a68899527ce41a84",
      "de9656c44a9747db8009d1bbc5bb1e57",
      "63b30ba94c9b47c3ab98b249f63f0258",
      "d82b83fd067b46a98f50a7339a024aed",
      "0d892d7272434c85ae5377dcc8053705",
      "a667cfbc4bb1446aa830fa902e86a410",
      "ff2ee28153084902b101a064ed19976e",
      "9e1cbae5cf74407497b724df8a6130d3",
      "656c73e18f4b4d9abd0b205ab12d1e53",
      "cbbe355ac371469f8ba0c8651f9fd45a",
      "e0eb4ebeeacc4dbd860f03fb2422efe7",
      "c849682cf1db4ae39547fd198feb7e70",
      "e261ccc38e0b4261a4bc2353f8df091c",
      "e48f5b4cb4514c6495b3a4154de2b047",
      "bca70bf6fc2543e2b947e04e0e05f08f",
      "bc0920d04baf4faaa0cc2e0063db0269",
      "87b1a6c4f9fd4f549d8268acfd44429e",
      "a1b4fbbde27249ac83465a41b68660c1",
      "6332ea04360748cdb0ba1cef74189745",
      "526cf79b21904043bcc058c305c7fef8",
      "ded26b561f4940d48cb94be65d7f4503",
      "8de73ebb05ea42c2a75406350731592f",
      "5d74e4a7bb104effae2ba5ec7a2c939b",
      "0d63806b5f724beaa2b06584d708d51b",
      "205a734fcadd4b9fab3e38ffa4e5e6e2",
      "5ed6d24c30724292a88e44b47bb11c4a",
      "a1e7dac3f0a44ccead73ca8e7147c443",
      "591cc0f92e8e42ceadb31f859c4d5d62",
      "5034b036c30640af85ef5a3d2bd83a44",
      "962c875935d64681ab4ea3aca32c3309",
      "1c63d7116694494c84c66fe3d222f26e",
      "a01a1cf43ffa4cf9882d8fa111264aac",
      "77b991f31cc645bdaf65ed2eab76c396",
      "7620298d90604f049c15c281379080b0",
      "5ac7d65351814268b39953c73006a143",
      "03d98612f7274d8c9eaf6311375317bf",
      "9769206f25c0419a81451d5fb11dd0b9",
      "58d3363a96b24ca5a4b7e2904d46fde2",
      "29d176d0419d4737a98af5e40b947ef4",
      "3f854de45c02456a8d6f26b5cfeaf211",
      "46d8fa17f6ef488cab92c9f4bf126d12",
      "28e6d1a45c0847f0af5ab10ebd35d07a",
      "4a0a0bf7d01a4a03893b29347eb69553",
      "6cd6d378f9c643e69328a2b47d1a05ed",
      "f355096fad554a908b0beedadf73881d",
      "9a3e00f677524cbd851f8aeeb2d486b7",
      "806bd28543ca443faf06c7dc4a4d5f98",
      "445e26b2a9d14a9a84f4be2a6b9f197c",
      "9eae4976dee343ba8acac28401aea152"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2785,
     "status": "ok",
     "timestamp": 1763573123856,
     "user": {
      "displayName": "Mohamed Wacyl Meddour",
      "userId": "07424742655467060070"
     },
     "user_tz": 300
    },
    "id": "X_-GIWXNnQSN",
    "outputId": "85f9f355-b7c1-4d49-9a38-09d01efe2ac1"
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained tokenizer (GPT-2 tokenizer works well for English text)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token\n",
    "\n",
    "print(f\"Tokenizer loaded with vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"Special tokens: PAD={tokenizer.pad_token_id}, EOS={tokenizer.eos_token_id}\")\n",
    "\n",
    "test_iter = islice(dataset, 0, test_dataset_size)\n",
    "train_iter = islice(dataset, test_dataset_size, train_dataset_size+test_dataset_size)\n",
    "\n",
    "train_dataset = PHDataset(train_iter, tokenizer, max_length=1024, max_samples=train_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3356,
     "status": "ok",
     "timestamp": 1763573127213,
     "user": {
      "displayName": "Mohamed Wacyl Meddour",
      "userId": "07424742655467060070"
     },
     "user_tz": 300
    },
    "id": "HpoGH5MancYB",
    "outputId": "20b94bd4-dd81-4e2c-8ec5-eab2a3264374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 164,394,240 parameters\n"
     ]
    }
   ],
   "source": [
    "training_config = TrainingConfig(vocab_size=tokenizer.vocab_size)\n",
    "# Create model config and initialize model\n",
    "model_config = TransformerConfig(\n",
    "    vocab_size=training_config.vocab_size,\n",
    "    hidden_size=training_config.hidden_size,\n",
    "    num_attention_heads=training_config.num_attention_heads,\n",
    "    num_hidden_layers=training_config.num_hidden_layers,\n",
    "    intermediate_size=training_config.intermediate_size,\n",
    "    max_position_embeddings=training_config.max_position_embeddings\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = PHCausalLanguageModel(model_config)\n",
    "print(f\"Model initialized with {count_parameters(model):,} parameters\")\n",
    "\n",
    "def get_lr_scheduler(optimizer, warmup_steps: int, total_steps: int):\n",
    "    \"\"\"Get learning rate scheduler with warmup\"\"\"\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        return max(0.0, float(total_steps - current_step) / float(max(1, total_steps - warmup_steps)))\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bRZMyRX_P9e"
   },
   "source": [
    "## Training Loop Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7OVAp-qK_P9e"
   },
   "outputs": [],
   "source": [
    "class PHTrainer:\n",
    "    def __init__(self, model, train_dataset, tokenizer, config: TrainingConfig):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "\n",
    "        # Setup device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        # Setup dataset for on-the-fly tokenization\n",
    "        self.train_dataset = train_dataset\n",
    "        self.batch_size = config.batch_size\n",
    "\n",
    "        # Setup optimizer and scheduler\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "\n",
    "        self.total_steps = (self.config.steps_per_epoch // self.batch_size) * config.num_epochs\n",
    "        self.scheduler = get_lr_scheduler(\n",
    "            self.optimizer,\n",
    "            config.warmup_steps,\n",
    "            self.total_steps\n",
    "        )\n",
    "\n",
    "        # Metrics\n",
    "        self.metrics = TrainingMetrics()\n",
    "        self.global_step = 0\n",
    "        os.makedirs(config.output_dir, exist_ok=True)\n",
    "        os.makedirs(config.log_dir, exist_ok=True)\n",
    "\n",
    "        self.log_file = os.path.join(config.log_dir, \"training_log.jsonl\")\n",
    "        with open(self.log_file, \"w\") as f:\n",
    "            f.write(json.dumps({\"event\": \"training_start\"}) + \"\\n\")\n",
    "\n",
    "    def train_step(self, batch) -> float:\n",
    "        \"\"\"\n",
    "        Single training step\n",
    "\n",
    "        Args:\n",
    "            batch: Batch of data\n",
    "\n",
    "        Returns:\n",
    "            loss: Training loss for this step\n",
    "        \"\"\"\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss, output = self.model(input_ids, labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def evaluate_step(self, batch) -> float:\n",
    "        \"\"\"Evaluation step\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "\n",
    "            loss, logits = self.model(input_ids, labels)\n",
    "            return loss.item()\n",
    "\n",
    "\n",
    "    def train(self, start_epoch = 0):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        print(f\"Starting training for {self.config.num_epochs} epochs\")\n",
    "        print(f\"Total steps: {self.total_steps}\")\n",
    "        print(f\"Warmup steps: {self.config.warmup_steps}\")\n",
    "        self.model.train()\n",
    "        for epoch in range(start_epoch, self.config.num_epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "\n",
    "            epoch_loss = 0\n",
    "            num_batches = self.config.steps_per_epoch // self.batch_size\n",
    "\n",
    "            dataset = datasets.load_dataset(\"openwebtext\", split=\"train\", streaming=True)\n",
    "            train_slice = islice(dataset, self.config.test_dataset_size, self.config.test_dataset_size + self.config.train_dataset_size)\n",
    "            train_dataset = PHDataset(train_slice, tokenizer, max_length=512, max_samples=self.config.train_dataset_size)\n",
    "            train_iter = iter(train_dataset)\n",
    "\n",
    "            progress_bar = tqdm(range(num_batches), desc=f\"Epoch {epoch + 1}\")\n",
    "\n",
    "            for batch_idx in progress_bar:\n",
    "                batch = {\n",
    "                    'input_ids': [],\n",
    "                    'labels': []\n",
    "                }\n",
    "\n",
    "                for _ in range(self.batch_size):\n",
    "                    sample = next(train_iter)\n",
    "                    batch['input_ids'].append(sample['input_ids'])\n",
    "                    batch['labels'].append(sample['labels'])\n",
    "\n",
    "\n",
    "                batch['input_ids'] = torch.stack(batch['input_ids'])\n",
    "                batch['labels'] = torch.stack(batch['labels'])\n",
    "\n",
    "                loss = self.train_step(batch)\n",
    "                epoch_loss += loss\n",
    "\n",
    "                current_lr = self.scheduler.get_last_lr()[0]\n",
    "                self.metrics.update(loss, current_lr)\n",
    "                self.global_step += 1\n",
    "\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{loss:.4f}',\n",
    "                    'avg_loss': f'{self.metrics.get_avg_loss():.4f}',\n",
    "                    'lr': f'{current_lr:.2e}'\n",
    "                })\n",
    "\n",
    "                log_entry = {\n",
    "                    \"step\": self.global_step,\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"batch_idx\": batch_idx,\n",
    "                    \"loss\": float(loss),\n",
    "                    \"avg_loss\": float(self.metrics.get_avg_loss()),\n",
    "                    \"learning_rate\": float(current_lr),\n",
    "                }\n",
    "                with open(self.log_file, \"a\") as f:\n",
    "                    f.write(json.dumps(log_entry) + \"\\n\")\n",
    "\n",
    "                # Evaluate model\n",
    "                if self.global_step % self.config.eval_steps == 0:\n",
    "                    print(f\"\\nEvaluating model at step {self.global_step}:\")\n",
    "                    print(\"-\" * 50)\n",
    "                    evaluate_model(self.model, self.tokenizer, [\"Once upon a time\", \"The little girl\"])\n",
    "                    print(\"-\" * 50)\n",
    "                    checkpoint_path = os.path.join(\n",
    "                        self.config.output_dir,\n",
    "                        f\"checkpoint-{self.global_step}\"\n",
    "                    )\n",
    "                    save_model(self.model, self.tokenizer, self.optimizer, self.scheduler, checkpoint_path)\n",
    "                    self.model.train()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / num_batches\n",
    "            print(f\"Epoch {epoch + 1} completed. Average loss: {avg_epoch_loss:.4f}\")\n",
    "            epoch_summary = {\n",
    "                \"event\": \"epoch_end\",\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"avg_epoch_loss\": float(avg_epoch_loss)\n",
    "            }\n",
    "            with open(self.log_file, \"a\") as f:\n",
    "                f.write(json.dumps(epoch_summary) + \"\\n\")\n",
    "            checkpoint_path = os.path.join(\n",
    "                self.config.output_dir,\n",
    "                f\"checkpoint-epoch-{epoch+1}\"\n",
    "            )\n",
    "            save_model(self.model, self.tokenizer, self.optimizer, self.scheduler, checkpoint_path)\n",
    "        save_model(self.model, self.tokenizer, self.optimizer, self.scheduler, self.config.output_dir)\n",
    "        print(\"Training completed!\")\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jzfeRoi_P9e"
   },
   "source": [
    "## Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1331505,
     "status": "ok",
     "timestamp": 1762983999562,
     "user": {
      "displayName": "Mohamed Wacyl Meddour",
      "userId": "02181144851054563055"
     },
     "user_tz": 300
    },
    "id": "mm8Jx1bs_P9e",
    "outputId": "af26b4ed-cb72-4171-ce72-5889e5c5de1c"
   },
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = PHTrainer(model, train_dataset, tokenizer, training_config)\n",
    "\n",
    "# Print model info\n",
    "print(f\"Model has {count_parameters(model):,} trainable parameters\")\n",
    "\n",
    "if last_trained_epoch > 0:\n",
    "    CHECKPOINT_PATH = os.path.join(\n",
    "        training_config.output_dir,\n",
    "        f\"checkpoint-epoch-{last_trained_epoch}\"\n",
    "    )\n",
    "\n",
    "    model_file = os.path.join(CHECKPOINT_PATH, \"model.pt\")\n",
    "    optimizer_file = os.path.join(CHECKPOINT_PATH, \"optimizer.pt\")\n",
    "    scheduler_file = os.path.join(CHECKPOINT_PATH, \"scheduler.pt\")\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        trainer.model.load_state_dict(torch.load(model_file, map_location=trainer.device))\n",
    "        trainer.optimizer.load_state_dict(torch.load(optimizer_file, map_location=trainer.device))\n",
    "        trainer.scheduler.load_state_dict(torch.load(scheduler_file, map_location=trainer.device))\n",
    "\n",
    "        steps_per_epoch = training_config.train_dataset_size // training_config.batch_size\n",
    "        start_global_step = last_trained_epoch * steps_per_epoch\n",
    "        trainer.global_step = start_global_step\n",
    "    else:\n",
    "        print(f\"\\n Checkpoint not found at {CHECKPOINT_PATH}. Starting training from scratch.\")\n",
    "\n",
    "trainer.train(last_trained_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqSzOmfd_P9e"
   },
   "source": [
    "## Model Evaluation and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1080344,
     "status": "ok",
     "timestamp": 1763574266407,
     "user": {
      "displayName": "Mohamed Wacyl Meddour",
      "userId": "07424742655467060070"
     },
     "user_tz": 300
    },
    "id": "X_qmH2uG_P9e",
    "outputId": "a9379053-c22d-44cc-ec47-8ac7cbad399e"
   },
   "outputs": [],
   "source": [
    "trainer = PHTrainer(model, train_dataset, tokenizer, training_config)\n",
    "model_dir = \"/transformer_ph\"\n",
    "test_prompts = [\n",
    "    \"Once upon a time\",\n",
    "    \"The little girl\",\n",
    "    \"In a magical forest\",\n",
    "    \"Every morning\"\n",
    "]\n",
    "load_model(model, model_dir)\n",
    "\n",
    "\n",
    "# Evaluate the trained model\n",
    "# evaluate_model(trainer.model, tokenizer, test_prompts)\n",
    "\n",
    "# Calculate perplexity\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERPLEXITY EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "avg_perplexity = calculate_perplexity(model, tokenizer, test_iter)\n",
    "print(f\"\\nFinal Average Perplexity: {avg_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wQzA8I0O252"
   },
   "outputs": [],
   "source": [
    "def plot_token_knn_graph(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    token_strs,\n",
    "    layer_idx: int = -1,\n",
    "    head_idx: int = 0,\n",
    "    k: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize kNN graph in WR(embedding) space for a few tokens\n",
    "\n",
    "    - token_strs: list of strings\n",
    "    - k: knn number\n",
    "    \"\"\"\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    embeddings = model.transformer.embeddings\n",
    "\n",
    "    head = model.transformer.transformer[layer_idx].mha.heads[head_idx]\n",
    "    WR = head.WR\n",
    "\n",
    "    vocab_size = model.config.vocab_size\n",
    "    vocab = torch.arange(vocab_size, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vecs = embeddings(vocab) @ WR.weight.T\n",
    "\n",
    "    vecs_np = vecs.detach().cpu().numpy()\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    coords = pca.fit_transform(vecs_np)  # (V, 2)\n",
    "    def token_to_id(s: str) -> int:\n",
    "        ids = tokenizer.encode(s, add_special_tokens=False)\n",
    "        if len(ids) == 0:\n",
    "            raise ValueError(f\"Token string {repr(s)} encodes to empty id list\")\n",
    "        if len(ids) > 1:\n",
    "            print(f\"Warning: {repr(s)} -> {ids} (using first id {ids[0]})\")\n",
    "        return ids[0]\n",
    "\n",
    "    center_ids = [token_to_id(s) for s in token_strs]\n",
    "\n",
    "    def knn_for_id(tid: int, k: int):\n",
    "        v = vecs_np[tid]  # (repn_dim,)\n",
    "        dists = np.linalg.norm(vecs_np - v, axis=1)  # (V,)\n",
    "        idx = np.argsort(dists)[:k + 1]              # include self\n",
    "        idx = [i for i in idx if i != tid][:k]       # drop self\n",
    "        return idx\n",
    "\n",
    "    edges = []\n",
    "    neighbor_ids = set()\n",
    "    for cid in center_ids:\n",
    "        neigh = knn_for_id(cid, k)\n",
    "        for nid in neigh:\n",
    "            edges.append((cid, nid))\n",
    "            neighbor_ids.add(nid)\n",
    "\n",
    "    # nodes = centers \\cup neighbors\n",
    "    all_nodes = sorted(set(center_ids) | neighbor_ids)\n",
    "\n",
    "    x = coords[all_nodes, 0]\n",
    "    y = coords[all_nodes, 1]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for (i, j) in edges:\n",
    "        xi, yi = coords[i]\n",
    "        xj, yj = coords[j]\n",
    "        plt.plot([xi, xj], [yi, yj], alpha=0.2, linewidth=0.8)\n",
    "\n",
    "    center_mask = np.isin(all_nodes, center_ids)\n",
    "    neighbor_mask = ~center_mask\n",
    "\n",
    "    plt.scatter(x[neighbor_mask], y[neighbor_mask],\n",
    "                s=20, alpha=0.6, label=\"neighbors\")\n",
    "    plt.scatter(x[center_mask], y[center_mask],\n",
    "                s=80, alpha=0.9, label=\"centers\")\n",
    "\n",
    "    id_to_token = tokenizer.convert_ids_to_tokens\n",
    "\n",
    "    for idx, tid in enumerate(all_nodes):\n",
    "        if tid in center_ids:\n",
    "            plt.text(x[idx], y[idx],\n",
    "                     id_to_token([tid])[0],\n",
    "                     fontsize=10, weight=\"bold\")\n",
    "        else:\n",
    "            # plt.text(x[idx], y[idx],\n",
    "            #          id_to_token([tid])[0],\n",
    "            #          fontsize=6, alpha=0.6)\n",
    "            pass\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f\"kNN graph in WR space (layer {layer_idx}, head {head_idx}, k={k})\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1763578350897,
     "user": {
      "displayName": "Mohamed Wacyl Meddour",
      "userId": "07424742655467060070"
     },
     "user_tz": 300
    },
    "id": "x8s_pBa-PnIW",
    "outputId": "48e5c8f0-4fff-4a69-e2da-2d7ed811f9cc"
   },
   "outputs": [],
   "source": [
    "plot_token_knn_graph(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    token_strs=[\"doctor\", \"the\", \"prof\", \"and\"],\n",
    "    layer_idx=-1,\n",
    "    head_idx=1,\n",
    "    k=25,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zmLnUrtQ_P9c"
   ],
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1fMwRFUiqLYBCOu0onyIxCNrmFvEotHIz",
     "timestamp": 1760365142371
    },
    {
     "file_id": "1scX-uB-gfC3WrbHpIjC53Bw3MnWbcXAh",
     "timestamp": 1758891234136
    },
    {
     "file_id": "1VTsBhtRyVzDxKzY7kkvO4WEn2WJWyhKS",
     "timestamp": 1758846551220
    },
    {
     "file_id": "17MRscB2ra1Dzg7kq5XEDTZy2MoOqQeQX",
     "timestamp": 1757966867897
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03d98612f7274d8c9eaf6311375317bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0508a805320e4b4d8c7d3410e52e7c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09a29d17df674f01a23b9267fd458a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a96728fefb5449496806bca2c544a0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37bd2023b2fb476cbcd4640f8423bba8",
      "placeholder": "",
      "style": "IPY_MODEL_61cc246856b44c71a68899527ce41a84",
      "value": "tokenizer_config.json:100%"
     }
    },
    "0d63806b5f724beaa2b06584d708d51b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d892d7272434c85ae5377dcc8053705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17a6ae837e5041cfafddd5f21dee5c3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c63d7116694494c84c66fe3d222f26e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9769206f25c0419a81451d5fb11dd0b9",
      "placeholder": "",
      "style": "IPY_MODEL_58d3363a96b24ca5a4b7e2904d46fde2",
      "value": "456k/456k[00:00&lt;00:00,6.42MB/s]"
     }
    },
    "205a734fcadd4b9fab3e38ffa4e5e6e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "28e6d1a45c0847f0af5ab10ebd35d07a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_445e26b2a9d14a9a84f4be2a6b9f197c",
      "placeholder": "",
      "style": "IPY_MODEL_9eae4976dee343ba8acac28401aea152",
      "value": "1.36M/1.36M[00:00&lt;00:00,10.0MB/s]"
     }
    },
    "29d176d0419d4737a98af5e40b947ef4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f854de45c02456a8d6f26b5cfeaf211",
       "IPY_MODEL_46d8fa17f6ef488cab92c9f4bf126d12",
       "IPY_MODEL_28e6d1a45c0847f0af5ab10ebd35d07a"
      ],
      "layout": "IPY_MODEL_4a0a0bf7d01a4a03893b29347eb69553"
     }
    },
    "328cef6191204f3e94d4242035d1c2ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "375354433c264d68bbb3af9e186e877d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37bd2023b2fb476cbcd4640f8423bba8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f854de45c02456a8d6f26b5cfeaf211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cd6d378f9c643e69328a2b47d1a05ed",
      "placeholder": "",
      "style": "IPY_MODEL_f355096fad554a908b0beedadf73881d",
      "value": "tokenizer.json:100%"
     }
    },
    "3fec9cb83a4140b8b8491a9214195d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d82b83fd067b46a98f50a7339a024aed",
      "placeholder": "",
      "style": "IPY_MODEL_0d892d7272434c85ae5377dcc8053705",
      "value": "26.0/26.0[00:00&lt;00:00,688B/s]"
     }
    },
    "445e26b2a9d14a9a84f4be2a6b9f197c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46d8fa17f6ef488cab92c9f4bf126d12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a3e00f677524cbd851f8aeeb2d486b7",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_806bd28543ca443faf06c7dc4a4d5f98",
      "value": 1355256
     }
    },
    "49040a59df664a2db3c17411200caff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0bc93ebf5c54636b6800e60ef1d70e2",
      "placeholder": "",
      "style": "IPY_MODEL_0508a805320e4b4d8c7d3410e52e7c21",
      "value": "7.35k/?[00:00&lt;00:00,411kB/s]"
     }
    },
    "4a0a0bf7d01a4a03893b29347eb69553": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5034b036c30640af85ef5a3d2bd83a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77b991f31cc645bdaf65ed2eab76c396",
      "placeholder": "",
      "style": "IPY_MODEL_7620298d90604f049c15c281379080b0",
      "value": "merges.txt:100%"
     }
    },
    "526cf79b21904043bcc058c305c7fef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ed6d24c30724292a88e44b47bb11c4a",
      "placeholder": "",
      "style": "IPY_MODEL_a1e7dac3f0a44ccead73ca8e7147c443",
      "value": "1.04M/1.04M[00:00&lt;00:00,8.51MB/s]"
     }
    },
    "5526feace396405a82db63a98ced30f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5628be3526df4351a3a5cf94e47745bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a34e2990c8544d74a1fe03ae2a0d4065",
      "placeholder": "",
      "style": "IPY_MODEL_17a6ae837e5041cfafddd5f21dee5c3a",
      "value": "openwebtext.py:"
     }
    },
    "5711a06b34b14746afa43ce406ce4dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5885030f40514cfc820bddf20066a798": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "58d3363a96b24ca5a4b7e2904d46fde2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "591cc0f92e8e42ceadb31f859c4d5d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5034b036c30640af85ef5a3d2bd83a44",
       "IPY_MODEL_962c875935d64681ab4ea3aca32c3309",
       "IPY_MODEL_1c63d7116694494c84c66fe3d222f26e"
      ],
      "layout": "IPY_MODEL_a01a1cf43ffa4cf9882d8fa111264aac"
     }
    },
    "5ac7d65351814268b39953c73006a143": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d74e4a7bb104effae2ba5ec7a2c939b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ed6d24c30724292a88e44b47bb11c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61cc246856b44c71a68899527ce41a84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6255af0f1ef9417c99947d01ccfa5152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de9656c44a9747db8009d1bbc5bb1e57",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_63b30ba94c9b47c3ab98b249f63f0258",
      "value": 26
     }
    },
    "6332ea04360748cdb0ba1cef74189745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d63806b5f724beaa2b06584d708d51b",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_205a734fcadd4b9fab3e38ffa4e5e6e2",
      "value": 1042301
     }
    },
    "63b30ba94c9b47c3ab98b249f63f0258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "656c73e18f4b4d9abd0b205ab12d1e53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bca70bf6fc2543e2b947e04e0e05f08f",
      "placeholder": "",
      "style": "IPY_MODEL_bc0920d04baf4faaa0cc2e0063db0269",
      "value": "665/665[00:00&lt;00:00,14.3kB/s]"
     }
    },
    "6cd6d378f9c643e69328a2b47d1a05ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7260ce838d23451ba3b1353a0df4cbb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c78a5cdfcc80435798749ba565d322be",
      "placeholder": "",
      "style": "IPY_MODEL_09a29d17df674f01a23b9267fd458a32",
      "value": "README.md:"
     }
    },
    "7620298d90604f049c15c281379080b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7638dd52ee9042c7a6e2c1df86c6b9dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a96728fefb5449496806bca2c544a0e",
       "IPY_MODEL_6255af0f1ef9417c99947d01ccfa5152",
       "IPY_MODEL_3fec9cb83a4140b8b8491a9214195d19"
      ],
      "layout": "IPY_MODEL_375354433c264d68bbb3af9e186e877d"
     }
    },
    "77b991f31cc645bdaf65ed2eab76c396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "806bd28543ca443faf06c7dc4a4d5f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "851d70362c3f4c26b7a7d2f6fb7b5437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "87b1a6c4f9fd4f549d8268acfd44429e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1b4fbbde27249ac83465a41b68660c1",
       "IPY_MODEL_6332ea04360748cdb0ba1cef74189745",
       "IPY_MODEL_526cf79b21904043bcc058c305c7fef8"
      ],
      "layout": "IPY_MODEL_ded26b561f4940d48cb94be65d7f4503"
     }
    },
    "8de73ebb05ea42c2a75406350731592f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "962c875935d64681ab4ea3aca32c3309": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ac7d65351814268b39953c73006a143",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03d98612f7274d8c9eaf6311375317bf",
      "value": 456318
     }
    },
    "9769206f25c0419a81451d5fb11dd0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a3e00f677524cbd851f8aeeb2d486b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1cbae5cf74407497b724df8a6130d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e261ccc38e0b4261a4bc2353f8df091c",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e48f5b4cb4514c6495b3a4154de2b047",
      "value": 665
     }
    },
    "9eae4976dee343ba8acac28401aea152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a01a1cf43ffa4cf9882d8fa111264aac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1b4fbbde27249ac83465a41b68660c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8de73ebb05ea42c2a75406350731592f",
      "placeholder": "",
      "style": "IPY_MODEL_5d74e4a7bb104effae2ba5ec7a2c939b",
      "value": "vocab.json:100%"
     }
    },
    "a1e7dac3f0a44ccead73ca8e7147c443": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a34e2990c8544d74a1fe03ae2a0d4065": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a667cfbc4bb1446aa830fa902e86a410": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff2ee28153084902b101a064ed19976e",
       "IPY_MODEL_9e1cbae5cf74407497b724df8a6130d3",
       "IPY_MODEL_656c73e18f4b4d9abd0b205ab12d1e53"
      ],
      "layout": "IPY_MODEL_cbbe355ac371469f8ba0c8651f9fd45a"
     }
    },
    "b96a0bb4e33f42d88196088d17902387": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7260ce838d23451ba3b1353a0df4cbb0",
       "IPY_MODEL_f1fd811e4785435fa33de6cbac5593fa",
       "IPY_MODEL_49040a59df664a2db3c17411200caff2"
      ],
      "layout": "IPY_MODEL_c708368d6e494fd4a1d5220e19028e6a"
     }
    },
    "bc0920d04baf4faaa0cc2e0063db0269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bca70bf6fc2543e2b947e04e0e05f08f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bef19581a0b4433085fb277806243098": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdab7e2797c543e39dbace5b167f5f38",
      "placeholder": "",
      "style": "IPY_MODEL_5711a06b34b14746afa43ce406ce4dda",
      "value": "2.73k/?[00:00&lt;00:00,158kB/s]"
     }
    },
    "c0bc93ebf5c54636b6800e60ef1d70e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c708368d6e494fd4a1d5220e19028e6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c78a5cdfcc80435798749ba565d322be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c849682cf1db4ae39547fd198feb7e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbbe355ac371469f8ba0c8651f9fd45a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdab7e2797c543e39dbace5b167f5f38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d82b83fd067b46a98f50a7339a024aed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de9656c44a9747db8009d1bbc5bb1e57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ded26b561f4940d48cb94be65d7f4503": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df03abfda00c4d09b6d70d8f5146f2bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0eb4ebeeacc4dbd860f03fb2422efe7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e261ccc38e0b4261a4bc2353f8df091c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e48f5b4cb4514c6495b3a4154de2b047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f00513a3d5db40709ddefddddf091b82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5885030f40514cfc820bddf20066a798",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df03abfda00c4d09b6d70d8f5146f2bf",
      "value": 1
     }
    },
    "f03acc2297f64cbdba706836d01084af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5628be3526df4351a3a5cf94e47745bf",
       "IPY_MODEL_f00513a3d5db40709ddefddddf091b82",
       "IPY_MODEL_bef19581a0b4433085fb277806243098"
      ],
      "layout": "IPY_MODEL_5526feace396405a82db63a98ced30f5"
     }
    },
    "f1fd811e4785435fa33de6cbac5593fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_328cef6191204f3e94d4242035d1c2ad",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_851d70362c3f4c26b7a7d2f6fb7b5437",
      "value": 1
     }
    },
    "f355096fad554a908b0beedadf73881d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff2ee28153084902b101a064ed19976e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0eb4ebeeacc4dbd860f03fb2422efe7",
      "placeholder": "",
      "style": "IPY_MODEL_c849682cf1db4ae39547fd198feb7e70",
      "value": "config.json:100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
